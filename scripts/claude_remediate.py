#!/usr/bin/env python3
"""
Claude-Assisted Accessibility Remediation

This script processes the remediation input generated by the scanning pipeline
and applies fixes that require judgment (alt text, link text, heading structure, etc.)

This script is designed to be run by Claude or to generate prompts for Claude.

Usage:
    python claude_remediate.py --input remediation_input.json --output fixed/
    python claude_remediate.py --input remediation_input.json --generate-prompts prompts/
"""

import argparse
import base64
import json
import logging
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, List, Dict, Any

try:
    from bs4 import BeautifulSoup, NavigableString
except ImportError:
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "beautifulsoup4", "lxml", "-q"])
    from bs4 import BeautifulSoup, NavigableString

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class RemediationDecision:
    """A remediation decision made by Claude."""
    issue_index: int
    file: str
    category: str
    action: str  # 'fix', 'skip', 'flag_for_review'
    fix_type: str  # 'replace', 'add_attribute', 'restructure', etc.
    selector: str
    original_value: Optional[str]
    new_value: str
    rationale: str
    confidence: float  # 0.0 to 1.0


class AccessibilityRemediator:
    """Apply accessibility remediation decisions to HTML content."""
    
    def __init__(self, content_dir: Path, output_dir: Path):
        self.content_dir = content_dir
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.decisions_log = []
    
    def process_remediation_input(self, remediation_input: dict) -> dict:
        """
        Process remediation input and apply fixes.
        
        This method contains the logic that Claude would use to make decisions.
        When run by Claude, it can analyze images and context to generate
        appropriate fixes.
        """
        results = {
            'files_processed': 0,
            'issues_fixed': 0,
            'issues_skipped': 0,
            'issues_flagged': 0,
            'decisions': []
        }
        
        for task in remediation_input.get('html_tasks', []):
            file_path = self.content_dir / task['file']
            if not file_path.exists():
                logger.warning(f"File not found: {file_path}")
                continue
            
            content = self._read_file(file_path)
            if not content:
                continue
            
            soup = BeautifulSoup(content, 'html.parser')
            modified = False
            
            # Process each issue
            for i, issue in enumerate(task.get('issues', [])):
                if issue.get('auto_fixable'):
                    continue  # Already handled by auto-fix
                
                decision = self._make_remediation_decision(
                    issue, task, soup, i
                )
                
                if decision.action == 'fix':
                    if self._apply_fix(soup, decision):
                        modified = True
                        results['issues_fixed'] += 1
                    else:
                        results['issues_skipped'] += 1
                elif decision.action == 'flag_for_review':
                    results['issues_flagged'] += 1
                else:
                    results['issues_skipped'] += 1
                
                results['decisions'].append({
                    'file': task['file'],
                    'issue_index': i,
                    'category': issue.get('category'),
                    'action': decision.action,
                    'rationale': decision.rationale,
                    'confidence': decision.confidence
                })
            
            # Save modified file
            if modified:
                output_path = self.output_dir / task['file']
                output_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(str(soup))
                
                results['files_processed'] += 1
        
        return results
    
    def _make_remediation_decision(
        self, 
        issue: dict, 
        task: dict, 
        soup: BeautifulSoup,
        issue_index: int
    ) -> RemediationDecision:
        """
        Make a remediation decision based on issue type and context.
        
        This is where Claude's judgment is applied.
        """
        category = issue.get('category', 'other')
        selector = issue.get('selector', '')
        context = issue.get('context', '')
        
        if category == 'images':
            return self._decide_image_fix(issue, task, soup, issue_index)
        elif category == 'links':
            return self._decide_link_fix(issue, task, soup, issue_index)
        elif category == 'headings':
            return self._decide_heading_fix(issue, task, soup, issue_index)
        elif category == 'tables':
            return self._decide_table_fix(issue, task, soup, issue_index)
        elif category == 'contrast':
            return self._decide_contrast_fix(issue, task, soup, issue_index)
        elif category == 'forms':
            return self._decide_form_fix(issue, task, soup, issue_index)
        else:
            return RemediationDecision(
                issue_index=issue_index,
                file=task['file'],
                category=category,
                action='flag_for_review',
                fix_type='unknown',
                selector=selector,
                original_value=context,
                new_value='',
                rationale=f"Unknown issue category: {category}",
                confidence=0.0
            )
    
    def _decide_image_fix(
        self, 
        issue: dict, 
        task: dict, 
        soup: BeautifulSoup,
        issue_index: int
    ) -> RemediationDecision:
        """Decide how to fix image accessibility issues."""
        selector = issue.get('selector', '')
        context = issue.get('context', '')
        
        # Find the image element
        img = None
        if selector:
            try:
                img = soup.select_one(selector)
            except:
                pass
        
        if not img:
            # Try to find by context
            for candidate in soup.find_all('img'):
                if context and context in str(candidate):
                    img = candidate
                    break
        
        if not img:
            return RemediationDecision(
                issue_index=issue_index,
                file=task['file'],
                category='images',
                action='flag_for_review',
                fix_type='not_found',
                selector=selector,
                original_value=context,
                new_value='',
                rationale="Could not locate image element",
                confidence=0.0
            )
        
        src = img.get('src', '')
        current_alt = img.get('alt')
        
        # Check for image info in task
        image_info = None
        for img_data in task.get('images', []):
            if img_data.get('src') == src:
                image_info = img_data
                break
        
        # Generate alt text based on context and image analysis
        alt_text, confidence, rationale = self._generate_alt_text(
            img, src, current_alt, image_info, task
        )
        
        return RemediationDecision(
            issue_index=issue_index,
            file=task['file'],
            category='images',
            action='fix' if confidence > 0.5 else 'flag_for_review',
            fix_type='add_attribute',
            selector=selector,
            original_value=current_alt,
            new_value=alt_text,
            rationale=rationale,
            confidence=confidence
        )
    
    def _generate_alt_text(
        self, 
        img, 
        src: str, 
        current_alt: Optional[str],
        image_info: Optional[dict],
        task: dict
    ) -> tuple:
        """
        Generate appropriate alt text for an image.
        
        Returns: (alt_text, confidence, rationale)
        """
        # Check if decorative
        if self._is_decorative_image(img, src):
            return ('', 0.9, 'Image appears decorative (spacer, border, bullet)')
        
        # Check if image of text
        filename = Path(src).stem.lower()
        if any(x in filename for x in ['logo', 'banner', 'header', 'title']):
            # Try to extract text context
            parent_text = self._get_surrounding_text(img, max_chars=100)
            if parent_text:
                return (
                    f"{filename.replace('_', ' ').replace('-', ' ').title()}",
                    0.7,
                    f"Generated from filename; surrounding context: {parent_text[:50]}"
                )
        
        # Use context from image_info
        if image_info and image_info.get('context'):
            context = image_info['context']
            if 'Caption:' in context:
                caption = context.split('Caption:')[1].split('|')[0].strip()
                return (caption, 0.85, 'Using figure caption as alt text')
        
        # Try to infer from filename
        if filename and filename not in ['image', 'img', 'photo', 'picture', 'untitled']:
            # Clean up filename
            alt_from_filename = filename.replace('_', ' ').replace('-', ' ')
            alt_from_filename = re.sub(r'\d+$', '', alt_from_filename).strip()
            if len(alt_from_filename) > 3:
                return (
                    alt_from_filename.capitalize(),
                    0.5,
                    'Generated from filename - needs review'
                )
        
        # Check surrounding context
        surrounding = self._get_surrounding_text(img, max_chars=200)
        if surrounding and len(surrounding) > 20:
            # Use first sentence of surrounding text as hint
            first_sentence = surrounding.split('.')[0][:100]
            return (
                f"[Image related to: {first_sentence}]",
                0.3,
                'Generated from surrounding text - needs manual review'
            )
        
        return (
            '[Image description needed]',
            0.1,
            'Could not determine appropriate alt text - manual review required'
        )
    
    def _is_decorative_image(self, img, src: str) -> bool:
        """Check if an image appears to be decorative."""
        src_lower = src.lower()
        filename = Path(src).stem.lower()
        
        # Check filename patterns
        decorative_patterns = [
            'spacer', 'blank', 'pixel', 'dot', 'line', 'border',
            'bullet', 'arrow', 'divider', 'separator', 'bg', 'background'
        ]
        if any(pattern in filename for pattern in decorative_patterns):
            return True
        
        # Check dimensions (1x1 pixel images are spacers)
        width = img.get('width')
        height = img.get('height')
        if width and height:
            try:
                if int(width) <= 3 and int(height) <= 3:
                    return True
            except ValueError:
                pass
        
        # Check if in CSS background or decorative container
        parent = img.parent
        if parent:
            parent_class = parent.get('class', [])
            if isinstance(parent_class, list):
                parent_class = ' '.join(parent_class)
            if any(x in parent_class.lower() for x in ['decor', 'bg', 'ornament']):
                return True
        
        return False
    
    def _get_surrounding_text(self, element, max_chars: int = 200) -> str:
        """Get text surrounding an element."""
        text_parts = []
        
        # Get previous siblings' text
        for sibling in element.previous_siblings:
            if isinstance(sibling, NavigableString):
                text_parts.insert(0, sibling.strip())
            elif hasattr(sibling, 'get_text'):
                text_parts.insert(0, sibling.get_text(strip=True))
        
        # Get next siblings' text
        for sibling in element.next_siblings:
            if isinstance(sibling, NavigableString):
                text_parts.append(sibling.strip())
            elif hasattr(sibling, 'get_text'):
                text_parts.append(sibling.get_text(strip=True))
        
        # Get parent text
        parent = element.parent
        if parent:
            parent_text = parent.get_text(strip=True)
            if parent_text and parent_text not in text_parts:
                text_parts.append(parent_text)
        
        combined = ' '.join(filter(None, text_parts))
        return combined[:max_chars] if combined else ''
    
    def _decide_link_fix(
        self, 
        issue: dict, 
        task: dict, 
        soup: BeautifulSoup,
        issue_index: int
    ) -> RemediationDecision:
        """Decide how to fix link accessibility issues."""
        selector = issue.get('selector', '')
        context = issue.get('context', '')
        message = issue.get('message', '')
        
        # Find the link element
        link = None
        if selector:
            try:
                link = soup.select_one(selector)
            except:
                pass
        
        if not link:
            return RemediationDecision(
                issue_index=issue_index,
                file=task['file'],
                category='links',
                action='flag_for_review',
                fix_type='not_found',
                selector=selector,
                original_value=context,
                new_value='',
                rationale="Could not locate link element",
                confidence=0.0
            )
        
        href = link.get('href', '')
        current_text = link.get_text(strip=True)
        
        # Generate better link text
        new_text, confidence, rationale = self._generate_link_text(
            link, href, current_text, task
        )
        
        return RemediationDecision(
            issue_index=issue_index,
            file=task['file'],
            category='links',
            action='fix' if confidence > 0.6 else 'flag_for_review',
            fix_type='replace_text',
            selector=selector,
            original_value=current_text,
            new_value=new_text,
            rationale=rationale,
            confidence=confidence
        )
    
    def _generate_link_text(
        self, 
        link, 
        href: str, 
        current_text: str,
        task: dict
    ) -> tuple:
        """
        Generate appropriate link text.
        
        Returns: (link_text, confidence, rationale)
        """
        # Check if link contains only an image
        img = link.find('img')
        if img and not current_text:
            alt = img.get('alt', '')
            if alt:
                return (alt, 0.8, 'Using image alt text as link text')
            # Generate from href
            link_text = self._text_from_href(href)
            if link_text:
                return (link_text, 0.6, 'Generated from URL - image link')
        
        # Check for generic link text
        generic_texts = [
            'click here', 'here', 'read more', 'more', 'link', 'learn more',
            'continue', 'details', 'info', 'download', 'view'
        ]
        if current_text.lower().strip() in generic_texts:
            # Try to generate from href
            link_text = self._text_from_href(href)
            if link_text:
                return (link_text, 0.7, f'Replaced generic "{current_text}" with descriptive text')
            
            # Try to get context from surrounding text
            surrounding = self._get_surrounding_text(link, 50)
            if surrounding:
                return (
                    f'{current_text}: {surrounding[:30]}',
                    0.5,
                    'Added context from surrounding text'
                )
        
        # Check for URL as link text
        if current_text.startswith(('http://', 'https://', 'www.')):
            link_text = self._text_from_href(href)
            if link_text:
                return (link_text, 0.7, 'Replaced URL with descriptive text')
        
        # Link text seems okay
        if current_text and len(current_text) > 3:
            return (current_text, 0.9, 'Existing link text appears adequate')
        
        # Empty link
        link_text = self._text_from_href(href)
        if link_text:
            return (link_text, 0.6, 'Generated text for empty link')
        
        return ('[Link text needed]', 0.2, 'Could not determine appropriate link text')
    
    def _text_from_href(self, href: str) -> str:
        """Generate descriptive text from a URL."""
        if not href or href.startswith('#'):
            if href.startswith('#'):
                return f"Jump to {href[1:].replace('-', ' ').replace('_', ' ')}"
            return ''
        
        # Extract filename for documents
        path = href.split('?')[0].split('#')[0]
        filename = Path(path).stem
        ext = Path(path).suffix.lower()
        
        if ext in ['.pdf', '.doc', '.docx', '.ppt', '.pptx', '.xls', '.xlsx']:
            name = filename.replace('_', ' ').replace('-', ' ')
            return f"{name.title()} ({ext[1:].upper()})"
        
        if ext in ['.html', '.htm', '']:
            name = filename.replace('_', ' ').replace('-', ' ')
            if name and name not in ['index', 'default', 'home']:
                return name.title()
        
        # For external links, try to extract domain
        if href.startswith(('http://', 'https://')):
            try:
                from urllib.parse import urlparse
                parsed = urlparse(href)
                domain = parsed.netloc.replace('www.', '')
                if domain:
                    return f"Visit {domain}"
            except:
                pass
        
        return ''
    
    def _decide_heading_fix(
        self, 
        issue: dict, 
        task: dict, 
        soup: BeautifulSoup,
        issue_index: int
    ) -> RemediationDecision:
        """Decide how to fix heading hierarchy issues."""
        message = issue.get('message', '')
        
        # Heading fixes are complex and usually need full document restructuring
        return RemediationDecision(
            issue_index=issue_index,
            file=task['file'],
            category='headings',
            action='flag_for_review',
            fix_type='restructure',
            selector=issue.get('selector', ''),
            original_value=issue.get('context', ''),
            new_value='',
            rationale=f"Heading structure issue requires document review: {message}",
            confidence=0.3
        )
    
    def _decide_table_fix(
        self, 
        issue: dict, 
        task: dict, 
        soup: BeautifulSoup,
        issue_index: int
    ) -> RemediationDecision:
        """Decide how to fix table accessibility issues."""
        selector = issue.get('selector', '')
        message = issue.get('message', '')
        
        # Find table
        table = None
        if selector:
            try:
                table = soup.select_one(selector)
            except:
                pass
        
        if not table:
            # Try to find any table
            tables = soup.find_all('table')
            if len(tables) == 1:
                table = tables[0]
        
        if not table:
            return RemediationDecision(
                issue_index=issue_index,
                file=task['file'],
                category='tables',
                action='flag_for_review',
                fix_type='not_found',
                selector=selector,
                original_value='',
                new_value='',
                rationale="Could not locate table element",
                confidence=0.0
            )
        
        # Check what's missing
        fixes_needed = []
        
        # Check for caption
        if not table.find('caption'):
            fixes_needed.append('caption')
        
        # Check for headers
        headers = table.find_all('th')
        if not headers:
            fixes_needed.append('headers')
        else:
            # Check for scope attributes
            for th in headers:
                if not th.get('scope'):
                    fixes_needed.append('scope')
                    break
        
        if fixes_needed:
            return RemediationDecision(
                issue_index=issue_index,
                file=task['file'],
                category='tables',
                action='flag_for_review',
                fix_type='add_table_structure',
                selector=selector,
                original_value=str(table)[:200],
                new_value=f"Needs: {', '.join(fixes_needed)}",
                rationale=f"Table needs {', '.join(fixes_needed)}",
                confidence=0.5
            )
        
        return RemediationDecision(
            issue_index=issue_index,
            file=task['file'],
            category='tables',
            action='skip',
            fix_type='none',
            selector=selector,
            original_value='',
            new_value='',
            rationale="Table structure appears adequate",
            confidence=0.8
        )
    
    def _decide_contrast_fix(
        self, 
        issue: dict, 
        task: dict, 
        soup: BeautifulSoup,
        issue_index: int
    ) -> RemediationDecision:
        """Decide how to fix color contrast issues."""
        # Contrast fixes require visual judgment and design consideration
        return RemediationDecision(
            issue_index=issue_index,
            file=task['file'],
            category='contrast',
            action='flag_for_review',
            fix_type='style_change',
            selector=issue.get('selector', ''),
            original_value=issue.get('context', ''),
            new_value='',
            rationale="Color contrast issue requires visual review and design decision",
            confidence=0.2
        )
    
    def _decide_form_fix(
        self, 
        issue: dict, 
        task: dict, 
        soup: BeautifulSoup,
        issue_index: int
    ) -> RemediationDecision:
        """Decide how to fix form accessibility issues."""
        selector = issue.get('selector', '')
        message = issue.get('message', '')
        
        return RemediationDecision(
            issue_index=issue_index,
            file=task['file'],
            category='forms',
            action='flag_for_review',
            fix_type='add_label',
            selector=selector,
            original_value=issue.get('context', ''),
            new_value='',
            rationale=f"Form element needs label association: {message}",
            confidence=0.4
        )
    
    def _apply_fix(self, soup: BeautifulSoup, decision: RemediationDecision) -> bool:
        """Apply a remediation fix to the document."""
        if decision.fix_type == 'add_attribute' and decision.category == 'images':
            return self._apply_alt_text_fix(soup, decision)
        elif decision.fix_type == 'replace_text' and decision.category == 'links':
            return self._apply_link_text_fix(soup, decision)
        
        return False
    
    def _apply_alt_text_fix(self, soup: BeautifulSoup, decision: RemediationDecision) -> bool:
        """Apply alt text fix to an image."""
        img = None
        if decision.selector:
            try:
                img = soup.select_one(decision.selector)
            except:
                pass
        
        if img:
            img['alt'] = decision.new_value
            return True
        
        return False
    
    def _apply_link_text_fix(self, soup: BeautifulSoup, decision: RemediationDecision) -> bool:
        """Apply link text fix."""
        link = None
        if decision.selector:
            try:
                link = soup.select_one(decision.selector)
            except:
                pass
        
        if link and decision.new_value:
            # Check if link contains only an image
            img = link.find('img')
            if img and not link.get_text(strip=True):
                img['alt'] = decision.new_value
            else:
                link.string = decision.new_value
            return True
        
        return False
    
    def _read_file(self, file_path: Path) -> Optional[str]:
        """Read file with encoding detection."""
        for encoding in ['utf-8', 'latin-1', 'cp1252']:
            try:
                with open(file_path, encoding=encoding) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue
        return None


def generate_claude_prompts(remediation_input: dict, output_dir: Path):
    """
    Generate prompts for Claude to review and fix issues.
    
    Creates individual prompt files for each file that needs remediation.
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    for i, task in enumerate(remediation_input.get('html_tasks', [])):
        if not task.get('issues'):
            continue
        
        prompt = f"""# Accessibility Remediation Task

## File: {task['file']}

## Issues Found:
"""
        
        for j, issue in enumerate(task.get('issues', [])):
            if issue.get('auto_fixable'):
                continue
            
            prompt += f"""
### Issue {j+1}: {issue.get('category', 'unknown').title()}
- **Type:** {issue.get('type', 'error')}
- **Code:** {issue.get('code', 'N/A')}
- **Message:** {issue.get('message', 'N/A')}
- **Context:** `{issue.get('context', 'N/A')[:200]}`
- **Hint:** {issue.get('remediation_hint', 'N/A')}
"""
        
        # Add images that need alt text
        images_needing_alt = [img for img in task.get('images', []) if img.get('needs_alt')]
        if images_needing_alt:
            prompt += """
## Images Needing Alt Text:
"""
            for img in images_needing_alt:
                prompt += f"""
- **Source:** {img.get('src')}
- **Current alt:** {img.get('current_alt', 'None')}
- **Context:** {img.get('context', 'No context available')}
"""
        
        prompt += """
## Instructions:
1. Review each issue and determine the appropriate fix
2. For images, generate descriptive alt text based on context
3. For links, make link text descriptive of the destination
4. For headings, ensure proper hierarchy (h1 > h2 > h3)
5. For tables, add appropriate headers, scope, and captions

## Content Preview:
```html
"""
        prompt += (task.get('content_preview', '')[:3000] or 'Content not available')
        prompt += """
```

## Your Response:
Provide fixes in JSON format:
```json
{
  "fixes": [
    {
      "issue_index": 0,
      "action": "fix",
      "selector": "img[src='example.png']",
      "attribute": "alt",
      "value": "Descriptive alt text here",
      "rationale": "Why this fix is appropriate"
    }
  ]
}
```
"""
        
        prompt_file = output_dir / f"prompt_{i:03d}_{Path(task['file']).stem}.md"
        with open(prompt_file, 'w') as f:
            f.write(prompt)
    
    logger.info(f"Generated prompts in {output_dir}")


def main():
    parser = argparse.ArgumentParser(description='Claude-Assisted Accessibility Remediation')
    parser.add_argument('--input', required=True, help='Remediation input JSON file')
    parser.add_argument('--content-dir', help='Content directory (default: from input)')
    parser.add_argument('--output', default='./remediated', help='Output directory')
    parser.add_argument('--generate-prompts', help='Generate prompts for Claude review')
    parser.add_argument('--apply-fixes', help='Apply fixes from JSON file')
    parser.add_argument('--dry-run', action='store_true', help='Show what would be done')
    
    args = parser.parse_args()
    
    # Load remediation input
    with open(args.input) as f:
        remediation_input = json.load(f)
    
    content_dir = Path(args.content_dir) if args.content_dir else \
                  Path(remediation_input.get('course_info', {}).get('content_dir', '.'))
    
    if args.generate_prompts:
        generate_claude_prompts(remediation_input, Path(args.generate_prompts))
        return
    
    if args.apply_fixes:
        # Apply fixes from a JSON file
        with open(args.apply_fixes) as f:
            fixes = json.load(f)
        # TODO: Apply fixes
        logger.info("Fix application not yet implemented")
        return
    
    # Run automatic remediation
    output_dir = Path(args.output)
    remediator = AccessibilityRemediator(content_dir, output_dir)
    
    if args.dry_run:
        logger.info("Dry run - no changes will be made")
    
    results = remediator.process_remediation_input(remediation_input)
    
    # Save results
    results_file = output_dir / 'remediation_results.json'
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    logger.info(f"Remediation complete:")
    logger.info(f"  Files processed: {results['files_processed']}")
    logger.info(f"  Issues fixed: {results['issues_fixed']}")
    logger.info(f"  Issues flagged for review: {results['issues_flagged']}")
    logger.info(f"  Issues skipped: {results['issues_skipped']}")
    logger.info(f"Results saved to: {results_file}")


if __name__ == '__main__':
    main()
